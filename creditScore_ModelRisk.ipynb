{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **üìå Controlling Risks in a Credit Score Prediction Model**\n",
    "To ensure that the model is **responsible, fair, and reliable**, I would implement the following **risk mitigation strategies**:\n",
    "\n",
    "---\n",
    "\n",
    "## **1Ô∏è‚É£ Bias & Fairness Risks**\n",
    "üí° **Problem:** The model may discriminate against certain groups (e.g., gender, income level).  \n",
    "‚úÖ **Mitigation Strategies:**\n",
    "- **Fairness Metrics**: Evaluate **Disparate Impact, Statistical Parity, and Equalized Odds**.\n",
    "- **Bias Mitigation Techniques**:\n",
    "  - **Reweighing** (adjust sample weights).\n",
    "  - **Adversarial Debiasing** (reduce the ability of the model to infer protected attributes).\n",
    "  - **Disparate Impact Remover** (modifies data to remove bias before training).\n",
    "- **Monitor Fairness Over Time**: Track if bias reappears after deployment.\n",
    "\n",
    "---\n",
    "\n",
    "## **2Ô∏è‚É£ Explainability & Transparency Risks**\n",
    "üí° **Problem:** Customers and regulators need to understand **why** a decision was made.  \n",
    "‚úÖ **Mitigation Strategies:**\n",
    "- **SHAP (SHapley Additive Explanations)**:\n",
    "  - Explain which features influenced a prediction.\n",
    "  - Compare feature importance across demographic groups.\n",
    "- **LIME (Local Interpretable Model-Agnostic Explanations)**:\n",
    "  - Generate explanations for individual predictions.\n",
    "- **Counterfactual Explanations**:\n",
    "  - Show how small changes (e.g., higher credit utilization) could lead to a better score.\n",
    "\n",
    "---\n",
    "\n",
    "## **3Ô∏è‚É£ Data Privacy & Security Risks**\n",
    "üí° **Problem:** Credit score models use sensitive personal and financial data.  \n",
    "‚úÖ **Mitigation Strategies:**\n",
    "- **Remove Personally Identifiable Information (PII)** before training (e.g., Name, SSN).\n",
    "- **Encrypt Data** in storage and transit.\n",
    "- **Comply with GDPR/CCPA** regulations:\n",
    "  - Allow users to **request model explanations**.\n",
    "  - Provide an option for users to **contest decisions**.\n",
    "\n",
    "---\n",
    "\n",
    "## **4Ô∏è‚É£ Model Robustness & Reliability Risks**\n",
    "üí° **Problem:** The model might make **wrong predictions** due to poor generalization or changing customer behavior.  \n",
    "‚úÖ **Mitigation Strategies:**\n",
    "- **Monitor Model Drift**: If customer spending patterns change, retrain the model.\n",
    "- **Adversarial Testing**: Check how the model reacts to **unusual edge cases** (e.g., a millionaire with high credit utilization).\n",
    "- **Stress Testing**:\n",
    "  - Simulate **economic downturns** to see if predictions remain stable.\n",
    "  - Introduce **synthetic fraud cases** to test fraud detection capabilities.\n",
    "\n",
    "---\n",
    "\n",
    "## **5Ô∏è‚É£ Regulatory & Compliance Risks**\n",
    "üí° **Problem:** Credit scoring is regulated by laws like **ECOA (Equal Credit Opportunity Act)** and **GDPR (General Data Protection Regulation)**.  \n",
    "‚úÖ **Mitigation Strategies:**\n",
    "- **Fair Lending Compliance**: Ensure that **race, gender, marital status, and age** do not unfairly impact scores.\n",
    "- **Automated Compliance Audits**: Generate fairness and risk reports for regulators.\n",
    "- **Right to Explanation**:\n",
    "  - Allow customers to receive a **detailed explanation** of their score.\n",
    "  - Provide actionable insights on how to improve their score.\n",
    "\n",
    "---\n",
    "\n",
    "## **üöÄ Next Steps**\n",
    "Would you like me to:\n",
    "1. **Implement model monitoring** to detect fairness drift over time?\n",
    "2. **Generate counterfactual explanations** for individual customers?\n",
    "3. **Improve bias mitigation techniques** with **more advanced debiasing strategies**?\n",
    "\n",
    "Let me know how you'd like to proceed! üî•\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/inFairness/utils/ndcg.py:37: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  vect_normalized_discounted_cumulative_gain = vmap(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/inFairness/utils/ndcg.py:48: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  monte_carlo_vect_ndcg = vmap(vect_normalized_discounted_cumulative_gain, in_dims=(0,))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Bin labels must be one fewer than the number of bin edges",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m fico_labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVery Poor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFair\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGood\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVery Good\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExceptional\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     27\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEstimated_FICO_Score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip((df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCredit_Limit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg_Utilization_Ratio\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m20\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m), \u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m850\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCredit_Score_Category\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcut\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEstimated_FICO_Score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfico_bins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfico_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m le_class \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m     30\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCredit_Score_Category\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m le_class\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCredit_Score_Category\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/reshape/tile.py:257\u001b[0m, in \u001b[0;36mcut\u001b[0;34m(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m bins\u001b[38;5;241m.\u001b[39mis_monotonic_increasing:\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbins must increase monotonically.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 257\u001b[0m fac, bins \u001b[38;5;241m=\u001b[39m \u001b[43m_bins_to_cuts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_lowest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_lowest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mduplicates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mduplicates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mordered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mordered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _postprocess_for_cut(fac, bins, retbins, original)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/reshape/tile.py:493\u001b[0m, in \u001b[0;36m_bins_to_cuts\u001b[0;34m(x_idx, bins, right, labels, precision, include_lowest, duplicates, ordered)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(bins) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 493\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    494\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBin labels must be one fewer than the number of bin edges\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    495\u001b[0m         )\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(labels, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), CategoricalDtype):\n\u001b[1;32m    498\u001b[0m     labels \u001b[38;5;241m=\u001b[39m Categorical(\n\u001b[1;32m    499\u001b[0m         labels,\n\u001b[1;32m    500\u001b[0m         categories\u001b[38;5;241m=\u001b[39mlabels \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(labels)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    501\u001b[0m         ordered\u001b[38;5;241m=\u001b[39mordered,\n\u001b[1;32m    502\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Bin labels must be one fewer than the number of bin edges"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE  # Fixing class imbalance\n",
    "from fairlearn.metrics import selection_rate\n",
    "from aif360.sklearn.metrics import disparate_impact_ratio, statistical_parity_difference\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"BankChurners.csv\")\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for col in ['Attrition_Flag', 'Gender', 'Education_Level', 'Income_Category', 'Card_Category']:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "    \n",
    "# Define \"Credit Score\" using FICO Score Approximation\n",
    "fico_bins = [0, 300, 580, 670, 740, 800, 850]\n",
    "fico_labels = ['Very Poor', 'Fair', 'Good', 'Very Good', 'Exceptional']\n",
    "df['Estimated_FICO_Score'] = np.clip((df['Credit_Limit'] * (1 - df['Avg_Utilization_Ratio']) / 20).astype(int), 300, 850)\n",
    "df['Credit_Score_Category'] = pd.cut(df['Estimated_FICO_Score'], bins=fico_bins, labels=fico_labels)\n",
    "le_class = LabelEncoder()\n",
    "df['Credit_Score_Category'] = le_class.fit_transform(df['Credit_Score_Category'])\n",
    "print(df['Credit_Score_Category'].value_counts())\n",
    "\n",
    "# Define Features and Target for Classification\n",
    "X = df.drop(columns=['Credit_Score_Category', 'Estimated_FICO_Score'])\n",
    "y_class = df['Credit_Score_Category']\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_class, test_size=0.2, random_state=42, stratify=y_class)\n",
    "\n",
    "# Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Convert X_test_scaled (NumPy array) back to DataFrame with original column names\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X.columns, index=X_test.index)\n",
    "\n",
    "# Predict using the RandomForestClassifier\n",
    "y_pred = rf_clf.predict(X_test_scaled_df)\n",
    "\n",
    "# Print Model Accuracy\n",
    "print(\"Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Bias Detection Metrics\n",
    "protected_attribute = df.loc[X_test.index, 'Gender']  # Fetch original values before encoding\n",
    "protected_attribute = protected_attribute.map({0: \"Male\", 1: \"Female\"})  # Ensure correct mapping\n",
    "\n",
    "# Ensure indexing is correct\n",
    "protected_attribute = protected_attribute.loc[X_test.index]\n",
    "\n",
    "# Compute Selection Rates for Male & Female\n",
    "male_selection_rate = selection_rate(y_test[protected_attribute == \"Male\"], y_pred[protected_attribute == \"Male\"])\n",
    "female_selection_rate = selection_rate(y_test[protected_attribute == \"Female\"], y_pred[protected_attribute == \"Female\"])\n",
    "\n",
    "# Handle Zero Selection Rates\n",
    "if male_selection_rate == 0 or female_selection_rate == 0:\n",
    "    gender_disparate_impact = np.nan  # Avoid division by zero\n",
    "    print(\"‚ö†Ô∏è Warning: One of the gender groups has zero selection rate.\")\n",
    "else:\n",
    "    gender_disparate_impact = female_selection_rate / male_selection_rate\n",
    "\n",
    "# Display Bias Metrics\n",
    "print(\"\\nüîç Fairness Metrics:\")\n",
    "print(\"Male Selection Rate:\", male_selection_rate)\n",
    "print(\"Female Selection Rate:\", female_selection_rate)\n",
    "print(\"Gender Disparate Impact Ratio:\", gender_disparate_impact)\n",
    "\n",
    "# SHAP Explainability\n",
    "explainer = shap.TreeExplainer(rf_clf)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "shap_importance = np.abs(shap_values).mean(axis=0).flatten()\n",
    "\n",
    "if len(shap_importance) == len(X.columns):\n",
    "    shap_importance_df = pd.DataFrame({\n",
    "        \"Feature\": X.columns,\n",
    "        \"SHAP Importance\": shap_importance\n",
    "    }).sort_values(by=\"SHAP Importance\", ascending=False)\n",
    "\n",
    "    print(\"\\nüîë Feature Importance (SHAP Values):\")\n",
    "    print(shap_importance_df)\n",
    "else:\n",
    "    print(\"Error: Length of SHAP importance values does not match number of features.\")\n",
    "\n",
    "# Implement Bias mitigation using Fairlearn\n",
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "from fairlearn.metrics import demographic_parity_difference\n",
    "\n",
    "thresh_opt = ThresholdOptimizer(estimator=rf_clf, constraints=\"demographic_parity\")\n",
    "thresh_opt.fit(X_train_scaled, y_train, sensitive_features=protected_attribute)\n",
    "y_pred_fair = thresh_opt.predict(X_test_scaled)\n",
    "\n",
    "# Prediction Function for New Customer\n",
    "def predict_credit_score(new_customer):\n",
    "    new_customer_df = pd.DataFrame([new_customer])\n",
    "    new_customer_df = new_customer_df.reindex(columns=X.columns, fill_value=0)\n",
    "    for col in ['Gender', 'Education_Level', 'Income_Category', 'Card_Category']:\n",
    "        new_customer_df[col] = label_encoders[col].transform(new_customer_df[col])\n",
    "    new_customer_scaled = scaler.transform(new_customer_df)\n",
    "    prediction = rf_clf.predict(new_customer_scaled)\n",
    "    return le_class.inverse_transform([prediction[0]])[0]\n",
    "\n",
    "# New Customer Data\n",
    "new_customer_data = pd.read_csv(\"test_customer_data.csv\")\n",
    "\n",
    "# Predict Credit Score\n",
    "predicted_scores = new_customer_data.apply(predict_credit_score, axis=1)\n",
    "print(\"Predicted Credit Score Category:\", predicted_scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
